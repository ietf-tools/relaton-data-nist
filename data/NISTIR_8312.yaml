---
schema-version: v1.2.3
id: NISTIR8312
title:
- content: Four principles of explainable artificial intelligence
  language:
  - en
  script:
  - Latn
  format: text/plain
link:
- content: https://doi.org/10.6028/NIST.IR.8312
  type: doi
- content: https://nvlpubs.nist.gov/nistpubs/ir/2021/NIST.IR.8312.pdf
  type: pdf
type: standard
docid:
- id: NIST IR 8312
  type: NIST
  primary: true
- id: 10.6028/NIST.IR.8312
  type: DOI
date:
- type: published
  value: '2021-09-29'
contributor:
- person:
    name:
      given:
        forename:
        - content: P Jonathon
          script:
          - Latn
      surname:
        content: Phillips
        script:
        - Latn
    affiliation:
    - organization:
        name:
        - content: Information Technology Laboratory
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Carina A
          script:
          - Latn
      surname:
        content: Hahn
        script:
        - Latn
    affiliation:
    - organization:
        name:
        - content: Information Technology Laboratory
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Peter C
          script:
          - Latn
      surname:
        content: Fontana
        script:
        - Latn
    affiliation:
    - organization:
        name:
        - content: Information Technology Laboratory
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Amy N
          script:
          - Latn
      surname:
        content: Yates
        script:
        - Latn
    affiliation:
    - organization:
        name:
        - content: Information Technology Laboratory
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Kristen
          script:
          - Latn
      surname:
        content: Greene
        script:
        - Latn
    affiliation:
    - organization:
        name:
        - content: Information Technology Laboratory
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: David A
          script:
          - Latn
      surname:
        content: Broniatowski
        script:
        - Latn
    affiliation:
    - organization:
        name:
        - content: Information Technology Laboratory
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Mark A
          script:
          - Latn
      surname:
        content: Przybocki
        script:
        - Latn
    affiliation:
    - organization:
        name:
        - content: Information Technology Laboratory
  role:
  - type: author
- organization:
    name:
    - content: National Institute of Standards and Technology (U.S.)
    contact:
    - address:
        city: Gaithersburg
        state: MD
        country: US
  role:
  - type: publisher
revdate: '2021-09-29'
script:
- Latn
abstract:
- content: We introduce four principles for explainable artificial intelligence (AI)
    that comprise fundamental properties for explainable AI systems. We propose that
    explainable AI systems deliver accompanying evidence or reasons for outcomes and
    processes; provide explanations that are understandable to individual users; provide
    explanations that correctly reflect the system s process for generating the output;
    and that a system only operates under conditions for which it was designed and
    when it reaches sufficient confidence in its output. We have termed these four
    principles as explanation, meaningful, explanation accuracy, and knowledge limits,
    respectively. Through significant stakeholder engagement, these four principles
    were developed to encompass the multidisciplinary nature of explainable AI, including
    the fields of computer science, engineering, and psychology. Because one-sizefits-all
    explanations do not exist, different users will require different types of explanations.
    We present five categories of explanation and summarize theories of explainable
    AI. We give an overview of the algorithms in the field that cover the major classes
    of explainable algorithms. As a baseline comparison, we assess how well explanations
    provided by people follow our four principles. This assessment provides insights
    to the challenges of designing explainable AI systems.
  script:
  - Latn
  format: text/plain
series:
- title:
    content: NIST NISTIRs (Interagency/Internal Reports)
    format: text/plain
  abbreviation:
    content: IR
  number: '8312'
doctype: standard
ext:
  schema-version: v1.0.0
